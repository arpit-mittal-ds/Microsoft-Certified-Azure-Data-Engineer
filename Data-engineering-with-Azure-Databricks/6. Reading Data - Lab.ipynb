{"cells":[{"cell_type":"markdown","source":["# Reading Data Lab\n* The goal of this lab is to put into practice some of what you have learned about reading data with Apache Spark.\n* The instructions are provided below along with empty cells for you to do your work.\n* At the bottom of this notebook are additional cells that will help verify that your work is accurate."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7dca9818-6e34-437b-b345-4b88bb36194f"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Instructions\n0. Start with the file **dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv**, some random file you haven't seen yet.\n0. Read in the data and assign it to a `DataFrame` named **testDF**.\n0. Run the last cell to verify that the data was loaded correctly and to print its schema.\n0. The one untestable requirement is that you should be able to create the `DataFrame` and print its schema **without** executing a single job.\n\n**Note:** For the test to pass, the following columns should have the specified data types:\n * **prev_id**: integer\n * **curr_id**: integer\n * **n**: integer\n * **prev_title**: string\n * **curr_title**: string\n * **type**: string"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff5b5560-34d8-4b55-aab5-ee1c5c9defd2"}}},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10d43bcb-4489-4e3e-bf50-bb7c00fd9e7e"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"621eb7ae-9f4b-495b-9b0f-acf4b79a405e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Initialized classroom variables & functions...","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Initialized classroom variables & functions..."]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Datasets are already mounted to <b>/mnt/training</b> from <b>wasbs://training@dbtrainwestus.blob.core.windows.net/</b>","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Datasets are already mounted to <b>/mnt/training</b> from <b>wasbs://training@dbtrainwestus.blob.core.windows.net/</b>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Created user-specific database","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Created user-specific database"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using the database <b style=\"color:green\">joel_solliance_net_db</b>.","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Using the database <b style=\"color:green\">joel_solliance_net_db</b>."]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"All done!","textData":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["All done!"]}}],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Show Your Work"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"571efbd8-acac-44e1-b3fd-d600767b606a"}}},{"cell_type":"code","source":["# ANSWER\n\n# The students will actually need to do this in two steps.\nfileName = \"dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv\"\n\n# The first step will be to use inferSchema = true \n# It's the only way to figure out what the column and data types are\n(spark.read\n  .option(\"sep\", \"\\t\")\n  .option(\"header\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .csv(fileName)\n  .printSchema()\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9981d6e-5d2f-40f2-8283-46e381f126a6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- prev_id: integer (nullable = true)\n |-- curr_id: integer (nullable = true)\n |-- n: integer (nullable = true)\n |-- prev_title: string (nullable = true)\n |-- curr_title: string (nullable = true)\n |-- type: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- prev_id: integer (nullable = true)\n-- curr_id: integer (nullable = true)\n-- n: integer (nullable = true)\n-- prev_title: string (nullable = true)\n-- curr_title: string (nullable = true)\n-- type: string (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# ANSWER\n\nfrom pyspark.sql.types import *\n\n# The second step is to create the schema\nschema = StructType([\n    StructField(\"prev_id\", IntegerType(), False),\n    StructField(\"curr_id\", IntegerType(), False),\n    StructField(\"n\", IntegerType(), False),\n    StructField(\"prev_title\", StringType(), False),\n    StructField(\"curr_title\", StringType(), False),\n    StructField(\"type\", StringType(), False)\n])\n\nfileName = \"dbfs:/mnt/training/wikipedia/clickstream/2015_02_clickstream.tsv\"\n\n#The third step is to read the data in with the user-defined schema\ntestDF = (spark.read\n  .option(\"sep\", \"\\t\")\n  .option(\"header\", \"true\")\n  .schema(schema)\n  .csv(fileName)\n)\n\ntestDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22fcb248-275c-4e16-8763-b2fcc685c547"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"testDF","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"prev_id","nullable":true,"type":"integer"},{"metadata":{},"name":"curr_id","nullable":true,"type":"integer"},{"metadata":{},"name":"n","nullable":true,"type":"integer"},{"metadata":{},"name":"prev_title","nullable":true,"type":"string"},{"metadata":{},"name":"curr_title","nullable":true,"type":"string"},{"metadata":{},"name":"type","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- prev_id: integer (nullable = true)\n |-- curr_id: integer (nullable = true)\n |-- n: integer (nullable = true)\n |-- prev_title: string (nullable = true)\n |-- curr_title: string (nullable = true)\n |-- type: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- prev_id: integer (nullable = true)\n-- curr_id: integer (nullable = true)\n-- n: integer (nullable = true)\n-- prev_title: string (nullable = true)\n-- curr_title: string (nullable = true)\n-- type: string (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Verify Your Work\nRun the following cell to verify that your `DataFrame` was created properly.\n\n**Remember:** This should execute without triggering a single job."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8d303fe-0f82-471f-a26b-c486c94b41fc"}}},{"cell_type":"code","source":["testDF.printSchema()\n\ncolumns = testDF.dtypes\nassert len(columns) == 6, \"Expected 6 columns but found \" + str(len(columns))\n\nassert columns[0][0] == \"prev_id\",    \"Expected column 0 to be \\\"prev_id\\\" but found \\\"\" + columns[0][0] + \"\\\".\"\nassert columns[0][1] == \"int\",        \"Expected column 0 to be of type \\\"int\\\" but found \\\"\" + columns[0][1] + \"\\\".\"\n\nassert columns[1][0] == \"curr_id\",    \"Expected column 1 to be \\\"curr_id\\\" but found \\\"\" + columns[1][0] + \"\\\".\"\nassert columns[1][1] == \"int\",        \"Expected column 1 to be of type \\\"int\\\" but found \\\"\" + columns[1][1] + \"\\\".\"\n\nassert columns[2][0] == \"n\",          \"Expected column 2 to be \\\"n\\\" but found \\\"\" + columns[2][0] + \"\\\".\"\nassert columns[2][1] == \"int\",        \"Expected column 2 to be of type \\\"int\\\" but found \\\"\" + columns[2][1] + \"\\\".\"\n\nassert columns[3][0] == \"prev_title\", \"Expected column 3 to be \\\"prev_title\\\" but found \\\"\" + columns[3][0] + \"\\\".\"\nassert columns[3][1] == \"string\",     \"Expected column 3 to be of type \\\"string\\\" but found \\\"\" + columns[3][1] + \"\\\".\"\n\nassert columns[4][0] == \"curr_title\", \"Expected column 4 to be \\\"curr_title\\\" but found \\\"\" + columns[4][0] + \"\\\".\"\nassert columns[4][1] == \"string\",     \"Expected column 4 to be of type \\\"string\\\" but found \\\"\" + columns[4][1] + \"\\\".\"\n\nassert columns[5][0] == \"type\",       \"Expected column 5 to be \\\"type\\\" but found \\\"\" + columns[5][0] + \"\\\".\"\nassert columns[5][1] == \"string\",     \"Expected column 5 to be of type \\\"string\\\" but found \\\"\" + columns[5][1] + \"\\\".\"\n\nprint(\"Congratulations, all tests passed... that is if no jobs were triggered :-)\\n\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eed24e15-4845-4c04-b06b-528e12a484e0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- prev_id: integer (nullable = true)\n |-- curr_id: integer (nullable = true)\n |-- n: integer (nullable = true)\n |-- prev_title: string (nullable = true)\n |-- curr_title: string (nullable = true)\n |-- type: string (nullable = true)\n\nCongratulations, all tests passed... that is if no jobs were triggered :-)\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- prev_id: integer (nullable = true)\n-- curr_id: integer (nullable = true)\n-- n: integer (nullable = true)\n-- prev_title: string (nullable = true)\n-- curr_title: string (nullable = true)\n-- type: string (nullable = true)\n\nCongratulations, all tests passed... that is if no jobs were triggered :-)\n\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Solution - Reading Data 8 - Lab","dashboards":[],"language":"python","widgets":{},"notebookOrigID":42263567104227}},"nbformat":4,"nbformat_minor":0}
